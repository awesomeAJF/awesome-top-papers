Intro

# Index
[TransferLearning](#TransferLearning)
  - [Low-shot Learning](#Low-shot_Learning)

[Nueral Language Processing](#NueralLanguageProcessing)

+ [Word Embedding](#WordEmbedding)
+ [Text summarization](#TextSummarization)

# Coming soon
- [ ] [ICLR 2019] [[paper](https://openreview.net/pdf?id=ByeSdsC9Km)] [[code](https://github.com/cogentlabs/apl)] Adaptive Posterior Learning: few-shot learning with a surprise-based memory module

- [ ] [CVPR 2019] CANet: Class-Agnostic Segmentation Networks with Iterative Refinement and Attentive Few-Shot Learning
- [ ] [CVPR 2019] Dense Classification and Implanting for Few-Shot Learning
- [ ] [CVPR 2019] All You Need is a Few Shifts: Designing Efficient Convolutional Neural Networks for Image Classification
- [ ] [CVPR 2019 oral] LaSO: Label-Set Operations networks for multi-label few-shot learning

# DeepLearning
## VAE
- [x] [arXiv 2013] [[paper](https://arxiv.org/pdf/1312.6114.pdf)] [[code](https://github.com/bojone/vae)] Auto-Encoding Variational Bayes

- [ ] [ICLR 2019] [[paper](https://arxiv.org/abs/1806.02199)] [[code](https://github.com/ratschlab/SOM-VAE)] SOM-VAE: Interpretable Discrete Representation Learning on Time Series.

# TransferLearning
## Low-shot_Learning
**Survey**
  - [x] [ICLR 2019] [[paper](https://openreview.net/pdf?id=HkxLXnAcFQ)] [[code](https://github.com/wyharveychen/CloserLookFewShot)] A Closer Look at Few-shot Classification
**By Using Generated images**
  - [x] [ICCV 2017] [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Hariharan_Low-Shot_Visual_Recognition_ICCV_2017_paper.pdf)] [[code](https://github.com/facebookresearch/low-shot-shrink-hallucinate)] Low-shot Visual Recognition by Shrinking and Hallucinating Features
  - [x] [CVPR 2018] [[paper](http://openaccess.thecvf.com/content_cvpr_2018/papers/Wang_Low-Shot_Learning_From_CVPR_2018_paper.pdf)] Low-Shot Learning from Imaginary Data
  - [x] [NIPS 2018] [[paper](https://papers.nips.cc/paper/7376-low-shot-learning-via-covariance-preserving-adversarial-augmentation-networks.pdf)] Low-shot Learning via Covariance-Preserving Adversarial Augmentation Networks

**Special Architecture or Method**
  - [x] [CVPR 2018] [[paper](http://10.3.200.202/cache/2/03/openaccess.thecvf.com/d0a8b18c2009916407c2becbadc35bc7/Sung_Learning_to_Compare_CVPR_2018_paper.pdf)] [[code](https://github.com/floodsung/LearningToCompare_FSL)] Learning to Compare-Relation Network for Few-Shot Learning
  - [x] [NIPS 2017] [[paper](http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning.pdf)] [[code](https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch)] Prototypical Networks for Few-shot Learning
  - [x] [ICML 2017] [[paper](https://arxiv.org/pdf/1703.03400.pdf)] [[code](https://github.com/dragen1860/MAML-Pytorch)] Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks
  - [x] [NIPS 2016] [[paper](http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning.pdf)] [[code](https://github.com/gitabcworld/MatchingNetworks)] Matching Networks for One Shot Learning
  - [x] [ICML 2015] [[paper](http://openaccess.thecvf.com/content_ICCV_2017/papers/Hariharan_Low-Shot_Visual_Recognition_ICCV_2017_paper.pdf)] [[code](http://www.cs.toronto.edu/~gkoch/files/msc-thesis.pdf)] Siamese Neural Networks for One-Shot Image Recognition
  - [x] [ICLR 2019] [[paper](https://openreview.net/pdf?id=SyVuRiC5K7)] [[code](https://github.com/VDeamoV/TPN)] LEARNING TO PROPAGATE LABELS: TRANSDUCTIVE PROPAGATION NETWORK FOR FEW-SHOT LEARNING

# NueralLanguageProcessing

 ## Word Embedding

+ [x] [JMLR 2003] [[paper](<http://10.3.200.202/cache/12/03/www.jmlr.org/9633c9131df0a22183c7a64855a5d166/bengio03a.pdf>)] A Neural Probabilistic Language Model
+ [x] [NIPS 2013] [[paper](<https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf>)] Distributed Representations of Words and Phrases and their Compositionality
+ [x] [EMNLP 2014] [[paper]((https://nlp.stanford.edu/pubs/glove.pdf))] GloVe: Global Vectors for Word Representation
+ [x] [NIPS 2017] [[paper](<https://arxiv.org/pdf/1706.03762.pdf>)] [[code](https://github.com/tensorflow/tensor2tensor)] Attention Is All You Need
+ [x] [NAACL 2018] [[paper](<https://arxiv.org/pdf/1802.05365.pdf>)] Deep contextualized word representations
+ [x] [arXiv 2018] [[paper](https://arxiv.org/pdf/1810.04805.pdf)] [[code](<https://github.com/google-research/bert>)] BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding



## Text Summarization

+ [x] [arXiv 2018] [[paper](https://arxiv.org/pdf/1902.09243.pdf)] Pretraining-Based Natural Language Generation for Text Summarization

